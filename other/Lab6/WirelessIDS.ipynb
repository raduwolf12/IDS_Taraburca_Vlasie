{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-64</td>\n",
       "      <td>-56</td>\n",
       "      <td>-61</td>\n",
       "      <td>-66</td>\n",
       "      <td>-71</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-68</td>\n",
       "      <td>-57</td>\n",
       "      <td>-61</td>\n",
       "      <td>-65</td>\n",
       "      <td>-71</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-63</td>\n",
       "      <td>-60</td>\n",
       "      <td>-60</td>\n",
       "      <td>-67</td>\n",
       "      <td>-76</td>\n",
       "      <td>-85</td>\n",
       "      <td>-84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-61</td>\n",
       "      <td>-60</td>\n",
       "      <td>-68</td>\n",
       "      <td>-62</td>\n",
       "      <td>-77</td>\n",
       "      <td>-90</td>\n",
       "      <td>-80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-63</td>\n",
       "      <td>-65</td>\n",
       "      <td>-60</td>\n",
       "      <td>-63</td>\n",
       "      <td>-77</td>\n",
       "      <td>-81</td>\n",
       "      <td>-87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-64</td>\n",
       "      <td>-55</td>\n",
       "      <td>-63</td>\n",
       "      <td>-66</td>\n",
       "      <td>-76</td>\n",
       "      <td>-88</td>\n",
       "      <td>-83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-65</td>\n",
       "      <td>-61</td>\n",
       "      <td>-65</td>\n",
       "      <td>-67</td>\n",
       "      <td>-69</td>\n",
       "      <td>-87</td>\n",
       "      <td>-84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-61</td>\n",
       "      <td>-63</td>\n",
       "      <td>-58</td>\n",
       "      <td>-66</td>\n",
       "      <td>-74</td>\n",
       "      <td>-87</td>\n",
       "      <td>-82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-65</td>\n",
       "      <td>-60</td>\n",
       "      <td>-59</td>\n",
       "      <td>-63</td>\n",
       "      <td>-76</td>\n",
       "      <td>-86</td>\n",
       "      <td>-82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-62</td>\n",
       "      <td>-60</td>\n",
       "      <td>-66</td>\n",
       "      <td>-68</td>\n",
       "      <td>-80</td>\n",
       "      <td>-86</td>\n",
       "      <td>-91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-67</td>\n",
       "      <td>-61</td>\n",
       "      <td>-62</td>\n",
       "      <td>-67</td>\n",
       "      <td>-77</td>\n",
       "      <td>-83</td>\n",
       "      <td>-91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-65</td>\n",
       "      <td>-59</td>\n",
       "      <td>-61</td>\n",
       "      <td>-67</td>\n",
       "      <td>-72</td>\n",
       "      <td>-86</td>\n",
       "      <td>-81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-63</td>\n",
       "      <td>-57</td>\n",
       "      <td>-61</td>\n",
       "      <td>-65</td>\n",
       "      <td>-73</td>\n",
       "      <td>-84</td>\n",
       "      <td>-84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-66</td>\n",
       "      <td>-60</td>\n",
       "      <td>-65</td>\n",
       "      <td>-62</td>\n",
       "      <td>-70</td>\n",
       "      <td>-85</td>\n",
       "      <td>-83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-61</td>\n",
       "      <td>-59</td>\n",
       "      <td>-65</td>\n",
       "      <td>-63</td>\n",
       "      <td>-74</td>\n",
       "      <td>-89</td>\n",
       "      <td>-87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-67</td>\n",
       "      <td>-60</td>\n",
       "      <td>-59</td>\n",
       "      <td>-61</td>\n",
       "      <td>-71</td>\n",
       "      <td>-86</td>\n",
       "      <td>-91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-63</td>\n",
       "      <td>-56</td>\n",
       "      <td>-60</td>\n",
       "      <td>-62</td>\n",
       "      <td>-70</td>\n",
       "      <td>-84</td>\n",
       "      <td>-91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-60</td>\n",
       "      <td>-54</td>\n",
       "      <td>-59</td>\n",
       "      <td>-65</td>\n",
       "      <td>-73</td>\n",
       "      <td>-83</td>\n",
       "      <td>-84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-60</td>\n",
       "      <td>-58</td>\n",
       "      <td>-60</td>\n",
       "      <td>-61</td>\n",
       "      <td>-73</td>\n",
       "      <td>-84</td>\n",
       "      <td>-88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-62</td>\n",
       "      <td>-59</td>\n",
       "      <td>-63</td>\n",
       "      <td>-64</td>\n",
       "      <td>-70</td>\n",
       "      <td>-84</td>\n",
       "      <td>-84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-63</td>\n",
       "      <td>-59</td>\n",
       "      <td>-64</td>\n",
       "      <td>-66</td>\n",
       "      <td>-72</td>\n",
       "      <td>-84</td>\n",
       "      <td>-90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-65</td>\n",
       "      <td>-59</td>\n",
       "      <td>-66</td>\n",
       "      <td>-65</td>\n",
       "      <td>-68</td>\n",
       "      <td>-82</td>\n",
       "      <td>-85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-63</td>\n",
       "      <td>-56</td>\n",
       "      <td>-63</td>\n",
       "      <td>-65</td>\n",
       "      <td>-72</td>\n",
       "      <td>-82</td>\n",
       "      <td>-89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-67</td>\n",
       "      <td>-60</td>\n",
       "      <td>-66</td>\n",
       "      <td>-65</td>\n",
       "      <td>-75</td>\n",
       "      <td>-86</td>\n",
       "      <td>-87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-63</td>\n",
       "      <td>-57</td>\n",
       "      <td>-67</td>\n",
       "      <td>-66</td>\n",
       "      <td>-79</td>\n",
       "      <td>-86</td>\n",
       "      <td>-89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-66</td>\n",
       "      <td>-59</td>\n",
       "      <td>-64</td>\n",
       "      <td>-68</td>\n",
       "      <td>-68</td>\n",
       "      <td>-97</td>\n",
       "      <td>-83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-65</td>\n",
       "      <td>-61</td>\n",
       "      <td>-64</td>\n",
       "      <td>-68</td>\n",
       "      <td>-77</td>\n",
       "      <td>-86</td>\n",
       "      <td>-89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-66</td>\n",
       "      <td>-57</td>\n",
       "      <td>-65</td>\n",
       "      <td>-69</td>\n",
       "      <td>-78</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-67</td>\n",
       "      <td>-57</td>\n",
       "      <td>-64</td>\n",
       "      <td>-71</td>\n",
       "      <td>-75</td>\n",
       "      <td>-89</td>\n",
       "      <td>-87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-65</td>\n",
       "      <td>-62</td>\n",
       "      <td>-62</td>\n",
       "      <td>-65</td>\n",
       "      <td>-77</td>\n",
       "      <td>-84</td>\n",
       "      <td>-85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>-58</td>\n",
       "      <td>-55</td>\n",
       "      <td>-50</td>\n",
       "      <td>-54</td>\n",
       "      <td>-48</td>\n",
       "      <td>-80</td>\n",
       "      <td>-86</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>-61</td>\n",
       "      <td>-51</td>\n",
       "      <td>-52</td>\n",
       "      <td>-56</td>\n",
       "      <td>-47</td>\n",
       "      <td>-86</td>\n",
       "      <td>-90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>-60</td>\n",
       "      <td>-52</td>\n",
       "      <td>-51</td>\n",
       "      <td>-55</td>\n",
       "      <td>-48</td>\n",
       "      <td>-86</td>\n",
       "      <td>-90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>-63</td>\n",
       "      <td>-61</td>\n",
       "      <td>-49</td>\n",
       "      <td>-58</td>\n",
       "      <td>-46</td>\n",
       "      <td>-92</td>\n",
       "      <td>-83</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>-61</td>\n",
       "      <td>-54</td>\n",
       "      <td>-45</td>\n",
       "      <td>-54</td>\n",
       "      <td>-43</td>\n",
       "      <td>-88</td>\n",
       "      <td>-80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>-57</td>\n",
       "      <td>-53</td>\n",
       "      <td>-45</td>\n",
       "      <td>-54</td>\n",
       "      <td>-52</td>\n",
       "      <td>-84</td>\n",
       "      <td>-82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>-56</td>\n",
       "      <td>-60</td>\n",
       "      <td>-47</td>\n",
       "      <td>-58</td>\n",
       "      <td>-46</td>\n",
       "      <td>-80</td>\n",
       "      <td>-82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>-55</td>\n",
       "      <td>-57</td>\n",
       "      <td>-43</td>\n",
       "      <td>-59</td>\n",
       "      <td>-53</td>\n",
       "      <td>-81</td>\n",
       "      <td>-85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>-55</td>\n",
       "      <td>-54</td>\n",
       "      <td>-43</td>\n",
       "      <td>-60</td>\n",
       "      <td>-51</td>\n",
       "      <td>-84</td>\n",
       "      <td>-88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>-56</td>\n",
       "      <td>-55</td>\n",
       "      <td>-45</td>\n",
       "      <td>-59</td>\n",
       "      <td>-52</td>\n",
       "      <td>-84</td>\n",
       "      <td>-86</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>-55</td>\n",
       "      <td>-54</td>\n",
       "      <td>-46</td>\n",
       "      <td>-60</td>\n",
       "      <td>-50</td>\n",
       "      <td>-84</td>\n",
       "      <td>-86</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>-56</td>\n",
       "      <td>-54</td>\n",
       "      <td>-47</td>\n",
       "      <td>-59</td>\n",
       "      <td>-52</td>\n",
       "      <td>-84</td>\n",
       "      <td>-91</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>-56</td>\n",
       "      <td>-55</td>\n",
       "      <td>-44</td>\n",
       "      <td>-61</td>\n",
       "      <td>-51</td>\n",
       "      <td>-84</td>\n",
       "      <td>-87</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>-57</td>\n",
       "      <td>-55</td>\n",
       "      <td>-48</td>\n",
       "      <td>-59</td>\n",
       "      <td>-51</td>\n",
       "      <td>-81</td>\n",
       "      <td>-86</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>-59</td>\n",
       "      <td>-54</td>\n",
       "      <td>-49</td>\n",
       "      <td>-58</td>\n",
       "      <td>-52</td>\n",
       "      <td>-83</td>\n",
       "      <td>-93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>-58</td>\n",
       "      <td>-53</td>\n",
       "      <td>-46</td>\n",
       "      <td>-59</td>\n",
       "      <td>-50</td>\n",
       "      <td>-86</td>\n",
       "      <td>-90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>-56</td>\n",
       "      <td>-55</td>\n",
       "      <td>-44</td>\n",
       "      <td>-60</td>\n",
       "      <td>-51</td>\n",
       "      <td>-84</td>\n",
       "      <td>-86</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>-56</td>\n",
       "      <td>-53</td>\n",
       "      <td>-43</td>\n",
       "      <td>-61</td>\n",
       "      <td>-58</td>\n",
       "      <td>-80</td>\n",
       "      <td>-85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>-57</td>\n",
       "      <td>-55</td>\n",
       "      <td>-50</td>\n",
       "      <td>-57</td>\n",
       "      <td>-49</td>\n",
       "      <td>-84</td>\n",
       "      <td>-85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>-56</td>\n",
       "      <td>-55</td>\n",
       "      <td>-54</td>\n",
       "      <td>-61</td>\n",
       "      <td>-46</td>\n",
       "      <td>-79</td>\n",
       "      <td>-79</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>-57</td>\n",
       "      <td>-54</td>\n",
       "      <td>-49</td>\n",
       "      <td>-61</td>\n",
       "      <td>-43</td>\n",
       "      <td>-79</td>\n",
       "      <td>-85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>-59</td>\n",
       "      <td>-53</td>\n",
       "      <td>-45</td>\n",
       "      <td>-57</td>\n",
       "      <td>-45</td>\n",
       "      <td>-81</td>\n",
       "      <td>-82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>-57</td>\n",
       "      <td>-56</td>\n",
       "      <td>-53</td>\n",
       "      <td>-62</td>\n",
       "      <td>-48</td>\n",
       "      <td>-87</td>\n",
       "      <td>-88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>-63</td>\n",
       "      <td>-55</td>\n",
       "      <td>-50</td>\n",
       "      <td>-63</td>\n",
       "      <td>-50</td>\n",
       "      <td>-91</td>\n",
       "      <td>-85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>-61</td>\n",
       "      <td>-54</td>\n",
       "      <td>-51</td>\n",
       "      <td>-63</td>\n",
       "      <td>-44</td>\n",
       "      <td>-87</td>\n",
       "      <td>-88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-59</td>\n",
       "      <td>-59</td>\n",
       "      <td>-48</td>\n",
       "      <td>-66</td>\n",
       "      <td>-50</td>\n",
       "      <td>-86</td>\n",
       "      <td>-94</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-59</td>\n",
       "      <td>-56</td>\n",
       "      <td>-50</td>\n",
       "      <td>-62</td>\n",
       "      <td>-47</td>\n",
       "      <td>-87</td>\n",
       "      <td>-90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-62</td>\n",
       "      <td>-59</td>\n",
       "      <td>-46</td>\n",
       "      <td>-65</td>\n",
       "      <td>-45</td>\n",
       "      <td>-87</td>\n",
       "      <td>-88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-62</td>\n",
       "      <td>-58</td>\n",
       "      <td>-52</td>\n",
       "      <td>-61</td>\n",
       "      <td>-41</td>\n",
       "      <td>-90</td>\n",
       "      <td>-85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-59</td>\n",
       "      <td>-50</td>\n",
       "      <td>-45</td>\n",
       "      <td>-60</td>\n",
       "      <td>-45</td>\n",
       "      <td>-88</td>\n",
       "      <td>-87</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1   2   3   4   5   6  7\n",
       "0    -64 -56 -61 -66 -71 -82 -81  1\n",
       "1    -68 -57 -61 -65 -71 -85 -85  1\n",
       "2    -63 -60 -60 -67 -76 -85 -84  1\n",
       "3    -61 -60 -68 -62 -77 -90 -80  1\n",
       "4    -63 -65 -60 -63 -77 -81 -87  1\n",
       "5    -64 -55 -63 -66 -76 -88 -83  1\n",
       "6    -65 -61 -65 -67 -69 -87 -84  1\n",
       "7    -61 -63 -58 -66 -74 -87 -82  1\n",
       "8    -65 -60 -59 -63 -76 -86 -82  1\n",
       "9    -62 -60 -66 -68 -80 -86 -91  1\n",
       "10   -67 -61 -62 -67 -77 -83 -91  1\n",
       "11   -65 -59 -61 -67 -72 -86 -81  1\n",
       "12   -63 -57 -61 -65 -73 -84 -84  1\n",
       "13   -66 -60 -65 -62 -70 -85 -83  1\n",
       "14   -61 -59 -65 -63 -74 -89 -87  1\n",
       "15   -67 -60 -59 -61 -71 -86 -91  1\n",
       "16   -63 -56 -60 -62 -70 -84 -91  1\n",
       "17   -60 -54 -59 -65 -73 -83 -84  1\n",
       "18   -60 -58 -60 -61 -73 -84 -88  1\n",
       "19   -62 -59 -63 -64 -70 -84 -84  1\n",
       "20   -63 -59 -64 -66 -72 -84 -90  1\n",
       "21   -65 -59 -66 -65 -68 -82 -85  1\n",
       "22   -63 -56 -63 -65 -72 -82 -89  1\n",
       "23   -67 -60 -66 -65 -75 -86 -87  1\n",
       "24   -63 -57 -67 -66 -79 -86 -89  1\n",
       "25   -66 -59 -64 -68 -68 -97 -83  1\n",
       "26   -65 -61 -64 -68 -77 -86 -89  1\n",
       "27   -66 -57 -65 -69 -78 -85 -85  1\n",
       "28   -67 -57 -64 -71 -75 -89 -87  1\n",
       "29   -65 -62 -62 -65 -77 -84 -85  1\n",
       "...   ..  ..  ..  ..  ..  ..  .. ..\n",
       "1970 -58 -55 -50 -54 -48 -80 -86  4\n",
       "1971 -61 -51 -52 -56 -47 -86 -90  4\n",
       "1972 -60 -52 -51 -55 -48 -86 -90  4\n",
       "1973 -63 -61 -49 -58 -46 -92 -83  4\n",
       "1974 -61 -54 -45 -54 -43 -88 -80  4\n",
       "1975 -57 -53 -45 -54 -52 -84 -82  4\n",
       "1976 -56 -60 -47 -58 -46 -80 -82  4\n",
       "1977 -55 -57 -43 -59 -53 -81 -85  4\n",
       "1978 -55 -54 -43 -60 -51 -84 -88  4\n",
       "1979 -56 -55 -45 -59 -52 -84 -86  4\n",
       "1980 -55 -54 -46 -60 -50 -84 -86  4\n",
       "1981 -56 -54 -47 -59 -52 -84 -91  4\n",
       "1982 -56 -55 -44 -61 -51 -84 -87  4\n",
       "1983 -57 -55 -48 -59 -51 -81 -86  4\n",
       "1984 -59 -54 -49 -58 -52 -83 -93  4\n",
       "1985 -58 -53 -46 -59 -50 -86 -90  4\n",
       "1986 -56 -55 -44 -60 -51 -84 -86  4\n",
       "1987 -56 -53 -43 -61 -58 -80 -85  4\n",
       "1988 -57 -55 -50 -57 -49 -84 -85  4\n",
       "1989 -56 -55 -54 -61 -46 -79 -79  4\n",
       "1990 -57 -54 -49 -61 -43 -79 -85  4\n",
       "1991 -59 -53 -45 -57 -45 -81 -82  4\n",
       "1992 -57 -56 -53 -62 -48 -87 -88  4\n",
       "1993 -63 -55 -50 -63 -50 -91 -85  4\n",
       "1994 -61 -54 -51 -63 -44 -87 -88  4\n",
       "1995 -59 -59 -48 -66 -50 -86 -94  4\n",
       "1996 -59 -56 -50 -62 -47 -87 -90  4\n",
       "1997 -62 -59 -46 -65 -45 -87 -88  4\n",
       "1998 -62 -58 -52 -61 -41 -90 -85  4\n",
       "1999 -59 -50 -45 -60 -45 -88 -87  4\n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adress='http://archive.ics.uci.edu/ml/machine-learning-databases/00422/wifi_localization.txt'\n",
    "dataframe=pd.read_csv(adress,sep=\"\\t\",header=None)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 7)\n",
      "(2000,)\n",
      "(400,)\n",
      "(1600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Florina\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x=dataframe.values[:,:-1]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x)\n",
    "x = scaler.transform(x)\n",
    "print(x.shape)\n",
    "y=dataframe.values[:, -1]\n",
    "print(y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=1/5, shuffle=True, random_state=42)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99038462 0.96216216 0.95081967 0.99107143]\n",
      "0.975\n",
      "{'n_neighbors': 3, 'p': 2}\n"
     ]
    }
   ],
   "source": [
    "parameter_grid = {'n_neighbors': list(range(1,10)), 'p': [1, 2, 3, 4.7]}\n",
    "grid_search = GridSearchCV(estimator = KNeighborsClassifier(), param_grid=parameter_grid, scoring='accuracy', cv=5, \n",
    "                           return_train_score=True, iid=False)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_estimated = grid_search.predict(X_test)\n",
    "print(f1_score(y_test, y_estimated, average=None))\n",
    "print(accuracy_score(y_test, y_estimated))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99496222 0.99380421 0.98669891 0.99481865]\n",
      "0.9925\n"
     ]
    }
   ],
   "source": [
    "y_estimated2 = grid_search.predict(X_train)\n",
    "print(f1_score(y_train, y_estimated2, average=None))\n",
    "print(accuracy_score(y_train, y_estimated2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Florina\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:271: UserWarning: The total space of parameters 36 is smaller than n_iter=100. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p': 2, 'n_neighbors': 3}\n",
      "0.975\n",
      "[0.99038462 0.96216216 0.95081967 0.99107143]\n"
     ]
    }
   ],
   "source": [
    "X_trainR, X_testR, y_trainR, y_testR = train_test_split(x, y, test_size=1/5,shuffle=True, random_state=42)\n",
    "gs_random = RandomizedSearchCV(estimator=KNeighborsClassifier(), param_distributions=parameter_grid, cv= 5,n_iter=100)\n",
    "gs_random.fit(X_trainR, y_trainR)\n",
    "print (gs_random.best_params_)\n",
    "y_estimated = gs_random.predict(X_test)\n",
    "print(accuracy_score(y_test, y_estimated))\n",
    "print(f1_score(y_test, y_estimated, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9925\n",
      "[0.99496222 0.99380421 0.98669891 0.99481865]\n"
     ]
    }
   ],
   "source": [
    "y_estimated2 = gs_random.predict(X_trainR)\n",
    "print(accuracy_score(y_trainR, y_estimated2))\n",
    "print(f1_score(y_trainR, y_estimated2, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Florina\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:271: UserWarning: The total space of parameters 36 is smaller than n_iter=100. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p': 2, 'n_neighbors': 3}\n",
      "0.975\n",
      "[0.99038462 0.96216216 0.95081967 0.99107143]\n"
     ]
    }
   ],
   "source": [
    "parameter_grid = {'n_neighbors': list(range(1,10)), 'p': [1, 2, 3, 4.7]}\n",
    "X_trainR, X_testR, y_trainR, y_testR = train_test_split(x, y, test_size=1/5, shuffle=True, random_state=42)\n",
    "gs_random = RandomizedSearchCV(estimator=KNeighborsClassifier(), param_distributions=parameter_grid, cv= 5,n_iter=100)\n",
    "gs_random.fit(X_trainR, y_trainR)\n",
    "print (gs_random.best_params_)\n",
    "y_estimated = gs_random.predict(X_testR)\n",
    "print(accuracy_score(y_testR, y_estimated))\n",
    "print(f1_score(y_testR, y_estimated, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9925\n",
      "[0.99496222 0.99380421 0.98669891 0.99481865]\n"
     ]
    }
   ],
   "source": [
    "y_estimated2 = gs_random.predict(X_trainR)\n",
    "print(accuracy_score(y_trainR, y_estimated2))\n",
    "print(f1_score(y_trainR, y_estimated2, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decizion Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9625\n",
      "{'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 4}\n",
      "[0.98095238 0.94179894 0.92045455 0.99555556]\n"
     ]
    }
   ],
   "source": [
    "X_trainT, X_testT, y_trainT, y_testT = train_test_split(x, y, test_size=1/5, shuffle=True, random_state=42)\n",
    "params = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "          'min_samples_split':list(range(2,15)), \n",
    "          'min_samples_leaf':list(range(2,11)),\n",
    "         }\n",
    "grid_search = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid=params, scoring='accuracy', cv=5, \n",
    "                           return_train_score=True, iid=False)\n",
    "grid_search.fit(X_trainT, y_trainT)\n",
    "y_estimated = grid_search.predict(X_testT)\n",
    "print(accuracy_score(y_testT, y_estimated))\n",
    "print(grid_search.best_params_)\n",
    "print(f1_score(y_testT, y_estimated, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n",
      "[0.9924812  0.99138991 0.98292683 0.99349805]\n"
     ]
    }
   ],
   "source": [
    "y_estimated2 = grid_search.predict(X_trainT)\n",
    "print(accuracy_score(y_trainT, y_estimated2))\n",
    "print(f1_score(y_trainT, y_estimated2, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "gs_random = RandomizedSearchCV(estimator=DecisionTreeClassifier(), param_distributions=params, cv= 5,n_iter=100)\n",
    "gs_random.fit(X_trainT, y_trainT)\n",
    "print (gs_random.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "{'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 7}\n",
      "[0.99038462 0.96216216 0.95081967 0.99107143]\n"
     ]
    }
   ],
   "source": [
    "y_estimated = gs_random.predict(X_testT)\n",
    "print(accuracy_score(y_testT, y_estimated))\n",
    "print(grid_search.best_params_)\n",
    "print(f1_score(y_testT, y_estimated, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9925\n",
      "[0.99496222 0.99380421 0.98669891 0.99481865]\n"
     ]
    }
   ],
   "source": [
    "y_estimated2 = gs_random.predict(X_trainT)\n",
    "print(accuracy_score(y_trainT, y_estimated2))\n",
    "print(f1_score(y_trainT, y_estimated2, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985\n",
      "{'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 25}\n",
      "[1.         0.97777778 0.96629213 0.99065421]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "paramsF = {'criterion':['gini','entropy'],\n",
    "          'n_estimators':[10,15,20,25,30],\n",
    "          'min_samples_leaf':[1,2,3],\n",
    "          'min_samples_split':[3,4,5,6,7]}\n",
    "X_trainF, X_testF, y_trainF, y_testF = train_test_split(x, y, test_size=1/5)\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid=paramsF, scoring='accuracy', cv=5, \n",
    "                           return_train_score=True, iid=False)\n",
    "grid_search.fit(X_trainF, y_trainF)\n",
    "y_estimated = grid_search.predict(X_testF)\n",
    "print(accuracy_score(y_testF, y_estimated))\n",
    "print(grid_search.best_params_)\n",
    "print(f1_score(y_testF, y_estimated, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996875\n",
      "{'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 25}\n",
      "[0.99740933 0.99632803 0.99514563 0.99872935]\n"
     ]
    }
   ],
   "source": [
    "y_estimated = grid_search.predict(X_trainF)\n",
    "print(accuracy_score(y_trainF, y_estimated))\n",
    "print(grid_search.best_params_)\n",
    "print(f1_score(y_trainF, y_estimated, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'min_samples_split': 4, 'min_samples_leaf': 3, 'criterion': 'gini'}\n",
      "0.985\n",
      "[1.         0.97777778 0.96629213 0.99065421]\n"
     ]
    }
   ],
   "source": [
    "gs_randomF = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=paramsF, cv= 5,n_iter=100)\n",
    "gs_randomF.fit(X_trainF, y_trainF)\n",
    "print (gs_randomF.best_params_)\n",
    "y_estimatedF = gs_randomF.predict(X_testF)\n",
    "print(accuracy_score(y_testF, y_estimatedF))\n",
    "print(f1_score(y_testF, y_estimatedF, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995625\n",
      "[0.99870298 0.99262899 0.99153567 1.        ]\n"
     ]
    }
   ],
   "source": [
    "y_estimatedF = gs_randomF.predict(X_trainF)\n",
    "print(accuracy_score(y_trainF, y_estimatedF))\n",
    "print(f1_score(y_trainF, y_estimatedF, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985\n",
      "{'C': 6, 'kernel': 'linear'}\n",
      "[1.         0.98019802 0.97087379 0.98947368]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "paramsS = {'C': [6,7,8,9,10,11,12], \n",
    "          'kernel': ['linear','rbf']}\n",
    "X_trainS, X_testS, y_trainS, y_testS = train_test_split(x, y, test_size=1/5)\n",
    "grid_searchS = GridSearchCV(estimator = svm.SVC(gamma='auto'), param_grid=paramsS, scoring='accuracy', cv=5, \n",
    "                           return_train_score=True, iid=False)\n",
    "grid_searchS.fit(X_trainS, y_trainS)\n",
    "y_estimatedS = grid_searchS.predict(X_testS)\n",
    "print(accuracy_score(y_testS, y_estimatedS))\n",
    "print(grid_searchS.best_params_)\n",
    "print(f1_score(y_testS, y_estimatedS, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98375\n",
      "[0.99374218 0.97567222 0.97044335 0.9950495 ]\n"
     ]
    }
   ],
   "source": [
    "y_estimatedS = grid_searchS.predict(X_trainS)\n",
    "print(accuracy_score(y_trainS, y_estimatedS))\n",
    "print(f1_score(y_trainS, y_estimatedS, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Florina\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:271: UserWarning: The total space of parameters 14 is smaller than n_iter=100. Running 14 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'C': 6}\n",
      "0.985\n",
      "[1.         0.98019802 0.97087379 0.98947368]\n"
     ]
    }
   ],
   "source": [
    "gs_randomS = RandomizedSearchCV(estimator=svm.SVC(gamma='auto'), param_distributions=paramsS, cv= 5,n_iter=100)\n",
    "gs_randomS.fit(X_trainS, y_trainS)\n",
    "print (gs_randomS.best_params_)\n",
    "y_estimatedS = gs_randomS.predict(X_testS)\n",
    "print(accuracy_score(y_testS, y_estimatedS))\n",
    "print(f1_score(y_testS, y_estimatedS, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98375\n",
      "[0.99374218 0.97567222 0.97044335 0.9950495 ]\n"
     ]
    }
   ],
   "source": [
    "y_estimatedS = gs_randomS.predict(X_trainS)\n",
    "print(accuracy_score(y_trainS, y_estimatedS))\n",
    "print(f1_score(y_trainS, y_estimatedS, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'alpha': [0.1, 0.001, 0.0001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "paramsM = {'activation' : ['identity', 'logistic', 'tanh', 'relu'], \n",
    "          'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "          'alpha':[0.1, 0.001, 0.0001]}\n",
    "X_trainM, X_testM, y_trainM, y_testM = train_test_split(x, y, test_size=1/5)\n",
    "grid_searchM = GridSearchCV(estimator = MLPClassifier(max_iter=10000), param_grid=paramsM, scoring='accuracy', cv=5, \n",
    "                           return_train_score=True, iid=False)\n",
    "grid_searchM.fit(X_trainM, y_trainM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "{'activation': 'relu', 'alpha': 0.001, 'solver': 'adam'}\n",
      "[0.98492462 0.97487437 0.94252874 0.99122807]\n"
     ]
    }
   ],
   "source": [
    "y_estimatedM = grid_searchM.predict(X_testM)\n",
    "print(accuracy_score(y_testM, y_estimatedM))\n",
    "print(grid_searchM.best_params_)\n",
    "print(f1_score(y_testM, y_estimatedM, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "[0.98492462 0.97487437 0.94252874 0.99122807]\n"
     ]
    }
   ],
   "source": [
    "y_estimatedM = grid_searchM.predict(X_testM)\n",
    "print(accuracy_score(y_testM, y_estimatedM))\n",
    "print(f1_score(y_testM, y_estimatedM, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Florina\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:271: UserWarning: The total space of parameters 36 is smaller than n_iter=100. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'lbfgs', 'alpha': 0.1, 'activation': 'tanh'}\n",
      "0.98\n",
      "[0.98989899 0.97512438 0.95402299 0.99559471]\n"
     ]
    }
   ],
   "source": [
    "gs_randomM = RandomizedSearchCV(estimator=MLPClassifier(max_iter=10000), param_distributions=paramsM, cv= 5,n_iter=100)\n",
    "gs_randomM.fit(X_trainM, y_trainM)\n",
    "print (gs_randomM.best_params_)\n",
    "y_estimatedM = gs_randomM.predict(X_testM)\n",
    "print(accuracy_score(y_testM, y_estimatedM))\n",
    "print(f1_score(y_testM, y_estimatedM, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984375\n",
      "[0.99626401 0.97610063 0.97218863 0.99354839]\n"
     ]
    }
   ],
   "source": [
    "y_estimatedM = gs_randomM.predict(X_trainM)\n",
    "print(accuracy_score(y_trainM, y_estimatedM))\n",
    "print(f1_score(y_trainM, y_estimatedM, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
